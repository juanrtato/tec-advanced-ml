{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5GAOvkm8ATN"
      },
      "source": [
        "# TC 5033\n",
        "## Deep Learning\n",
        "## Fully Connected Deep Neural Networks\n",
        "\n",
        "## Team Members\n",
        "- Luis Miguel Álvarez Caloca - A01732666\n",
        "- Juan Ricardo Albarracin Barbosa - A01794818\n",
        "\n",
        "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
        "\n",
        "- Objective\n",
        "\n",
        "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
        "\n",
        "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
        "\n",
        "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
        "\n",
        "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
        "    \n",
        "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
        "\n",
        "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
        "\n",
        "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
        "\n",
        "- Evaluation Criteria\n",
        "\n",
        "    - Code Readability and Comments\n",
        "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
        "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
        "    - Quality of Markdown documentation\n",
        "\n",
        "- Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fJrLw9D8ATP",
        "outputId": "c57a7204-42c1-4014-acaa-145b9bfafc58"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split # Team's choice for data splitting\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#################################\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11j8X-kxiO1"
      },
      "source": [
        "#### We decided importing train_test_split from Scikit-learn, a widely used library in machine learning.\n",
        "#### This function is reliable, well-tested, and considered a standard for dataset splitting.\n",
        "#### It simplifies the process of creating reproducible and well-balanced splits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBI-Rrnf8ATQ",
        "outputId": "e8a2afdc-62b8-42dd-b67c-22fc0e463657"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# to load the data using google colaboratory\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#DATA_PATH = '/home/pepe/Documents/github_repos/datasets/asl_data'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      5\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/My Drive/MAESTRÍA/TRIMESTRE 3/DEEP LEARNING/HW1/asl_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# to load the data using google colaboratory\n",
        "# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
        "#DATA_PATH = '/home/pepe/Documents/github_repos/datasets/asl_data'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = '/content/drive/My Drive/MAESTRÍA/TRIMESTRE 3/DEEP LEARNING/HW1/asl_data'\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
        "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to load the data in a local environment\n",
        "DATA_PATH = '../data/asl_data'\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
        "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "IFMpucLj8ATR",
        "outputId": "c1c21e86-2c3d-4f4c-96e6-91ebf3111ae8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     12     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFY-UwPt8ATR"
      },
      "source": [
        "### Importar Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y3CU5zjh8ATR"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_df['label'])\n",
        "y_val = np.array(valid_df['label'])\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "x_train = train_df.values.astype(np.float32)\n",
        "x_val = valid_df.values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((27455, 784), (27455,), (3586, 784), (3586,))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "code_folding": [],
        "id": "D2-As2158ATS"
      },
      "outputs": [],
      "source": [
        "def split_val_test(x: np.ndarray, y: np.ndarray, pct: float = 0.5, shuffle: bool = True) -> tuple:\n",
        "    '''\n",
        "    Split the previously loaded validation set into valition and test.\n",
        "\n",
        "    Args:\n",
        "      x (np.ndarray): The features of the dataset (input data, images or tabular data).\n",
        "      y (np.ndarray): The labels corresponding to the features (target values).\n",
        "      pct (float): The proportion of the dataset to allocate to the test set (default is 0.5 or 50%).\n",
        "      shuffle (bool): Whether to shuffle the dataset before splitting (default is True).\n",
        "        Setting shuffle = True ensures that the data is randomly mixed before splitting.\n",
        "        This prevents potential biases caused by ordered datasets (e.g., samples grouped by class).\n",
        "        It helps create representative validation and test sets, improving model evaluation and generalization.\n",
        "        Shuffle is a standard practice in most machine learning workflows unless the data is sequential (e.g., time series).\n",
        "    \n",
        "    Returns:\n",
        "      tuple: The split datasets in the following order: x_val, y_val, x_test, y_test\n",
        "    '''\n",
        "    x_val, x_test, y_val, y_test = train_test_split(\n",
        "        x, y, test_size=pct, shuffle=shuffle, random_state=42 # random_state=42 Ensures reproducibility by setting a fixed random seed for shuffling.\n",
        "    )\n",
        "    return x_val, y_val, x_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "#NOTE: version proposed by juan (more manual)\n",
        "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
        "    '''\n",
        "    Split the previously loaded validation set into valition and test.\n",
        "\n",
        "    Args:\n",
        "      x (np.ndarray): The features of the dataset (input data, images or tabular data).\n",
        "      y (np.ndarray): The labels corresponding to the features (target values).\n",
        "      pct (float): The proportion of the dataset to allocate to the test set (default is 0.5 or 50%).\n",
        "      shuffle (bool): Whether to shuffle the dataset before splitting (default is True).\n",
        "        Setting shuffle = True ensures that the data is randomly mixed before splitting.\n",
        "        This prevents potential biases caused by ordered datasets (e.g., samples grouped by class).\n",
        "        It helps create representative validation and test sets, improving model evaluation and generalization.\n",
        "        Shuffle is a standard practice in most machine learning workflows unless the data is sequential (e.g., time series).\n",
        "    \n",
        "    Returns:\n",
        "      tuple: The split datasets in the following order: x_val, y_val, x_test, y_test\n",
        "    '''\n",
        "    if shuffle:\n",
        "        idx = np.random.permutation(len(y))\n",
        "        x = x[idx]\n",
        "        y = y[idx]\n",
        "    split = int(len(y) * pct)\n",
        "    return x[:split], y[:split], x[split:], y[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3FlqP8vC8ATS"
      },
      "outputs": [],
      "source": [
        "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzQX9lIn8ATS",
        "outputId": "4a346406-0832-4452-cb35-7c753f74b1bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "### The following code is to remove the letters 'j' and 'z' from the alphabet\n",
        "alphabet=list(string.ascii_lowercase)\n",
        "alphabet.remove('j')\n",
        "alphabet.remove('z')\n",
        "print(len(alphabet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dzLd86V8ATS"
      },
      "source": [
        "### Normalise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBTBaFAH5Ufi",
        "outputId": "4b316468-8996-4e39-df43-5cd82b70ea02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.6268384e-06, 0.99999946)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def normalise(x_mean: float, x_std: float, x_data: np.ndarray) -> np.ndarray:\n",
        "    '''\n",
        "    Normalise the input data based on the mean and standard deviation.\n",
        "\n",
        "    Args:\n",
        "        x_mean (float): Mean of the input data.\n",
        "        x_std (float): Standard deviation of the input data.\n",
        "        x_data (np.ndarray): Input data.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Normalised input data.\n",
        "    '''\n",
        "    return (x_data - x_mean) / x_std\n",
        "\n",
        "x_mean = x_train.mean() # We calculate the mean of the training set\n",
        "x_std = x_train.std() # We calculate the standard deviation of the training set\n",
        "\n",
        "   # - We only use the training set to compute these statistics to avoid data leakage.\n",
        "   # - The validation and test sets must not influence the model during training.\n",
        "\n",
        "\n",
        "x_train = normalise(x_mean, x_std, x_train) # Normalizing the training set\n",
        "x_val = normalise(x_mean, x_std, x_val) # Normalizing the validation set using training stats\n",
        "x_test = normalise(x_mean, x_std, x_test) # Normalise the test set using training stats\n",
        "\n",
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SEAB2GREqH_"
      },
      "source": [
        "#### Mean expected value of ~0 and standard deviation of ~1\n",
        "#### Which in this case is correct, normalization was applied correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZhrl0RA8ATT"
      },
      "source": [
        "### Graficar muestras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will plot a random sample of images from the dataset to visualize the data. \n",
        "\n",
        "This step helps us understand the structure of the data and verify that the images are loaded correctly.\n",
        "\n",
        "We use two functions to plot the images. The first one plots a single image, while the second one plots a random sample of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_image(image: np.array, label: int):\n",
        "    \"\"\"\n",
        "    Plot a single image from the dataset.\n",
        "\n",
        "    Args:\n",
        "        image (numpy.ndarray): Image to plot.\n",
        "        label (int): Label of the image.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Create the figure using matplotlib\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "\n",
        "    # Reshape the image to 28x28\n",
        "    image = image.reshape(28, 28)\n",
        "\n",
        "    # Show the image and set the title\n",
        "    ax.imshow(image, cmap='gray')\n",
        "    ax.set_title(f\"Label: {alphabet[label]}\")\n",
        "    ax.axis('off')  # Hide axes\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_image(x_train[0], y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdIAAAFECAYAAAAjhszqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDZklEQVR4nO39ebBf9WHf/7/vvki62ne0IIQRq7EtNhuKTIwXzGDHMWA7bkKY2k3aTve0TjoNzh9tk0wSO9vEbtM4aTzN2CEOsTHGBpfFjDEgMEQsAgkhhC4I7brSvVd3/fz++I751QUfXh/riHslHo+ZzDS3T53z+Zzlfd7nrRvR0mg0GgUAAAAAAHhNrVP9AQAAAAAAYDqzkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJBOZPv27aWlpaX87u/+bm3bvPvuu0tLS0u5++67a9sm8OY0HceoDRs2lHPOOae2zwOc+KbjWFVKKX/1V39V1q1bVzo6OsqcOXNq+2zAiWG6jk3Am5dxienKQvpJ7C/+4i9KS0tL2bhx41R/FIBXMUYBJ4KTfazavHlzueGGG8ppp51W/sf/+B/lv//3/z7VHwkInOxjE3DiMS7xZtA+1R8AAACYGnfffXeZnJwsf/AHf1DWrl071R8HAACmLb+RDgAAb1K7d+8upRT/pAsAALwOC+lvcqOjo+U3fuM3yjve8Y4ye/bsMmPGjHLZZZeVu+666yf+mc997nNl1apVpaenp1x++eXl8ccff1WzefPm8tGPfrTMmzevdHd3l/Xr15evf/3rr/t5hoaGyubNm8vevXtft129enW54YYbXvXzDRs2lA0bNrzunwemvxN5jHot3/nOd0pvb2/5+Mc/XsbHx3+qbQDTz4k6Vq1evbrcdNNNpZRSFi5cWFpaWspnP/vZ190+cGI4Ucemf/Ev/kWZOXNmGRoaetX/38c//vGyZMmSMjEx8br7A6afE3VcKuX//9/A+od/+Idy+eWXl97e3rJ27dpy8803l1JKueeee8pFF11Uenp6yhlnnFHuvPPO190mJx4L6W9yAwMD5c/+7M/Khg0bym//9m+Xz372s2XPnj3lfe97X3n00Udf1f+v//W/yh/+4R+Wf/7P/3n5tV/7tfL444+XK664orz88suvNE888US5+OKLy1NPPVU+85nPlN/7vd8rM2bMKB/+8IfL3/3d31V+ngcffLCceeaZ5Y//+I/r/qrACehkGqNuvfXWcs0115Rrr722fPnLXy7t7f51NThZnKhj1ec///nysz/7s6WUUv70T/+0/NVf/VX5yEc+0vwBAKalE3Vsuv7668vg4GD55je/+WM/HxoaKt/4xjfKRz/60dLW1pYfCGDaOFHHpR85cOBAufrqq8tFF11Ufud3fqd0dXWVj33sY+UrX/lK+djHPlauuuqq8lu/9VtlcHCwfPSjHy2HDx9u6vhwAmhw0vrSl77UKKU0HnrooZ/YjI+PN0ZGRn7sZwcOHGgsXry4ceONN77ys+eee65RSmn09PQ0du7c+crPH3jggUYppfFv/s2/eeVnP/MzP9M499xzG0ePHn3lZ5OTk413vvOdjdNPP/2Vn911112NUkrjrrvuetXPbrrpptf9fqtWrWr84i/+4qt+fvnllzcuv/zy1/3zwNQ62ceoyy+/vHH22Wc3Go1G42//9m8bHR0djU996lONiYmJ1/2zwPRxso9VN910U6OU0tizZ8/rtsD0cTKPTZOTk43ly5c3fu7nfu7Hfv7Vr361UUpp3HvvvZV/HpgaJ/O41Gj8f+93pZTG//7f//uVn23evLlRSmm0trY2fvCDH7zy829/+9uNUkrjS1/60utulxOL30h/k2trayudnZ2llFImJyfL/v37y/j4eFm/fn155JFHXtV/+MMfLsuXL3/lf7/wwgvLRRddVG677bZSSin79+8v/+f//J9y3XXXlcOHD5e9e/eWvXv3ln379pX3ve99ZcuWLaW/v/8nfp4NGzaURqPh/6wYKKWcHGPUX//1X5frr7++/NN/+k/LF7/4xdLa6tELJ5uTYawCTj4n6tjU0tJSrr322nLbbbeVI0eOvPLzr3zlK2X58uXl0ksvbeYwANPIiTou/cjMmTPLxz72sVf+9zPOOKPMmTOnnHnmmeWiiy565ec/+n9v27Yt2i4nDm/zlL/8y78s5513Xunu7i7z588vCxcuLN/85jfLoUOHXtWefvrpr/rZW97ylrJ9+/ZSSilbt24tjUaj/Of//J/LwoULf+x/fvRvcP7oP2oFkDiRx6jnnnuufPKTnyw/93M/V/7oj/6otLS01LZtYHo5kccq4OR1oo5N119/fRkeHn7l3zg+cuRIue2228q1115rPgUnuBN1XCqllFNOOeVVY9Ds2bPLihUrXvWzUv6/fwqGk4t/oPVN7stf/nK54YYbyoc//OHyq7/6q2XRokWlra2t/Lf/9t/Ks88+2/T2JicnSyml/Pt//+/L+973vtds1q5de0yf+Ud+0gRqYmLCv5kHJ4kTeYwqpZSlS5eWpUuXlttuu61s3LixrF+/vrZtA9PHiT5WASenE3lsuvjii8vq1avLV7/61fKJT3yifOMb3yjDw8Pl+uuvr2X7wNQ4kcelUspPXGv6ST9vNBq17ZvpwUL6m9zNN99c1qxZU772ta/92ML0j/7m7v+1ZcuWV/3smWeeKatXry6llLJmzZpSSikdHR3lPe95T/0f+P8yd+7ccvDgwVf9/Pnnn3/lcwAnthN5jCqllO7u7nLrrbeWK664orz//e8v99xzTzn77LOP+36BN9aJPlYBJ6cTfWy67rrryh/8wR+UgYGB8pWvfKWsXr26XHzxxcd9v8Dxc6KPS+CfdnmT+9Hfmv3ff0v2wAMPlPvvv/81+1tuueXH/n2pBx98sDzwwAPlAx/4QCmllEWLFpUNGzaUL37xi+Wll1561Z/fs2dP5ecZGhoqmzdvLnv37n3dz37aaaeVH/zgB2V0dPSVn916663lhRdeeN0/C5wYTuQx6kdmz55dvv3tb5dFixaVK6+88qf6TQtgejsZxirg5HOij03XX399GRkZKX/5l39Zbr/99nLddddFfw6Yvk70cQn8RvqbwJ//+Z+X22+//VU//1f/6l+Vq6++unzta18rP/uzP1s++MEPlueee6584QtfKGedddaP/YddfmTt2rXl0ksvLb/yK79SRkZGyuc///kyf/788h/+w394pfmTP/mTcumll5Zzzz23fOpTnypr1qwpL7/8crn//vvLzp07y2OPPfYTP+uDDz5Y3v3ud5ebbrrpdf9jD//kn/yTcvPNN5f3v//95brrrivPPvts+fKXv1xOO+20/OAAU+5kHaP+bwsWLCh33HFHufTSS8t73vOect999/3YfzQHmP7eDGMVcOI5mcemt7/97WXt2rXlP/2n/1RGRkb8sy5wgjiZxyWwkP4m8Kd/+qev+fMbbrih3HDDDWXXrl3li1/8Yvn2t79dzjrrrPLlL3+5/M3f/E25++67X/VnfuEXfqG0traWz3/+82X37t3lwgsvLH/8x39cli5d+kpz1llnlY0bN5bf/M3fLH/xF39R9u3bVxYtWlTe9ra3ld/4jd+o7Xu9733vK7/3e79Xfv/3f7/863/9r8v69evLrbfeWv7dv/t3te0DOP5O1jHq/7V8+fJy5513lssuu6xceeWV5d577y0LFiw4bvsD6vVmGauAE8vJPjZdf/315b/8l/9S1q5dW97+9rfXvn2gfif7uMSbW0vDv3wPAAAAAAA/kX8jHQAAAAAAKlhIBwAAAACAChbSAQAAAACggoV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKBCexpedtllUdfR0RF1M2fOjLqlS5dG3fz586Oup6cn6ur+HqWU0t3dHXWdnZ1R196enb50e62t2d+r9Pb2Rl1bW1vUjY2NRV1LS0ut+001Go1at5d+j2b2nXaTk5O1dnXv90Mf+lDUvZb0fli3bl3Upddlet+kny/dXjpGpWNoKaUsWbIk6tLxtpnxMdHX1xd1s2fPjrp0bEy7rq6uqEvPXXrNpNtLu2bG0LRNr+u6x+90v6lzzjnnp/6zt9xyS9Slx6DuZ+KJ8Ixt5vlZ577Te3HXrl1Rl36PRYsWRd3IyEjUpc/iuk1MTNS6vWaumXTf6fvBI488EnW/9Vu/FXULFy6MuuXLl0fdfffdF3Wv5Utf+lLU1f1sSseUtJuq/R4Pg4ODUXfo0KGoW7lyZdSlY1Tdz9hU3c+C9HscjzE0Hc/q/s51S7/Hhg0bfup9/LN/9s+iru61irRL95t26ftHusbUzDbTcT49Nul+0/E7Nd3nwOnYU/f938z3qHt8rHv9qO4x9Iorrog6v5EOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFdrTsK2tLepaW7O1+c7Ozinp2tuzr9zV1RV13d3dUVdK/hk7Ojpq3V567pYuXRp1Tz/9dNSNj49H3emnnx51ExMTtXbptdpoNKKupaUl6poxOTkZdXV/xnS/6bFOr4Vjkd6LdZ+nusfG9POl+03HvOO1zURfX1/UpcdwZGQk6mbMmBF1qfT4pV36LEi7uvdbSn69pucu7eqWHps3QvpZ0mNf9zlKHY9zmX6XdIwaGhqKuoULF0bdo48+GnWbNm2Kuk9/+tNRNzo6GnXpcUnnFOkcIJ1Tp3OFZuYU6XdOj+Edd9xR6/bSY50+145Feqym6pmTfr507Kn7e5SSn890/jE4OBh13/jGN6LuxhtvjLrZs2dHXTomp8clVfdcvu45ejOm8j2zTnWf49dS9xgwVXPTqZwTT9W8fbrP79Munfek0v2m86h07tGMqRp70mum7rW/lN9IBwAAAACAChbSAQAAAACggoV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKCChXQAAAAAAKhgIR0AAAAAACpYSAcAAAAAgArtadjS0hJ1ra3Z2nxbW1vUdXR0RF17e/ZV0i7db1dXV9Q103Z2dtbaTU5ORt3y5cuj7rnnnou6f/iHf4i6RqMRdbNnz466VatWRd3IyEjU1S39vs20dXfp/Vl3dyx6enqiLh2jpspUjbXHa5uJdOw5cOBA1N15551R94EPfCDqlixZEnWp9PhN1fN0Kq+ZdHvpfZJ6I8aFuu+bqRor0u0dj2OafueBgYGoS+dlvb29UZeOUemxTr9v2qX7TecK6Zz60KFDUZeej3S/peRz5a1bt0bdli1boq6vry/qjse4/NOaqjGl7ne4up+JdT9vSsmvyxkzZkRdes/u3Lkz6hYsWBB1qfHx8ahLP9/evXujbv369VFX97V/PK6ZqZJeW2/Ed6577Kn7GVv3GJVu73gc+7rnFVN1T6TrYBMTE1E3f/78qEvnjT/84Q+jbmhoKOrOOuusqDse0mshPdap9Hlat+m9ogQAAAAAAFPMQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQoT0NW1paat1xR0dHrV17e/ZV0q6rqyvqOjs7o66ZNt132k1MTERdT09P1M2cOTPqFixYEHWLFy+Outtuuy3qPv3pT0dda2v290iNRiPqJicna91eM23dXSq9ttra2mrd72vp7u6OuvQ8TXfpWNbMsU/btEvH74GBgairewy99dZbo+7GG2+MuvQaTMee9Byn20vPW7q9ZrZZd1e3Zr7zTyudR9V9PtMu/Xx1X0cjIyNRV0opq1evjro77rgj6tJ5yumnnx51zz77bNS9853vjLpU3eckfU6mc4Dbb7896latWhV1l156adSVUsr4+HjU7dy5M+qGhoaiLr225syZE3W9vb1RdyzqfpdK5wB1j3npfuseG5uRfuf0vKfX0Y4dO6Ju/fr1UZe+V9T9/Pvud78bdenYPX/+/Kg7Huo+htN9e8fijdjHa3kj5ojHst+p+nyl5POF9DOm84rzzjsv6vr6+qLuySefjLqtW7dG3Qc/+MGoS+cUn/vc56Ju//79Uff+978/6kop5dChQ1GXPlPT9+WjR49GXd1jWcpvpAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAECF9jRsbc3W3FtaWmrdXltbW9S1t2dfJd1eR0dH1HV2dkZdKaV0dXVNyb4bjUat+x0ZGYm6/fv3R93atWuj7uDBg1H31FNPRd0FF1wQdYODg1GXXvvp+SillMnJyVq7uveb3sfNfOefVm9vb63bS79bqu7rIx3z0vu6mTY9NulnTO+xdMybP39+1PX390fd3/7t30bdL//yL0fd0aNHo26qnrvNXDPpM7Xuz5iq+xgei/Sz1D0/mqpjn2rm2Kffefny5VG3c+fOqDt8+HDUDQ0NRd2KFSuibnx8POrqvhYOHToUdVu3bo26p59+OurOO++8qDse0ufGwoULo27mzJlRl8630nNyLNLrqO5xNX3mpF36Per+vqXU/yxJP2N3d3fU7d69O+rSd9axsbGoS49LOs9Lj8u2bduibvHixVGXaua9LL2+6n43q/vd8WSWXr/pdZke+4mJiahL37dKmbq1ulQ6Bpx66qm17vfss8+Ouscffzzqbrrppqj75Cc/GXXvete7ou7mm2+Ouo985CNRV0p+fd1zzz1Rt2DBgqhbs2ZN1A0PD0dd7e+YtW4NAAAAAABOMhbSAQAAAACggoV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKCChXQAAAAAAKhgIR0AAAAAACpYSAcAAAAAgArtdW+wpaUl23F7tuvW1mytP+3S/dbdNdN2dHTUur30nIyNjUVdb29v1B0+fDjqRkZGom7OnDlR9/TTT0fdZZddFnWjo6NRl16DjUYj6kopZWJiovZtJiYnJ6ekOxbpfVO39P5Kz1F6HaX7bWtri7pm9p1uM91eeu66u7ujLv186ZiycePGqHv44Yej7l3velfUHT16NOq6urqiru5nSyn1P6PT6zrdXjr2pNs7FnU/s+s+Vs2MFYlmrqNU+jxesmRJ1PX399fapffi3Llzoy6dA3R2dkbd3r17o+7555+Puvvvvz/q1q1bF3Xnn39+1A0ODkZdKfmxWbZsWdSlz42650cHDx6MumORjgF1v8+k+027uvebjrWl1D8fT8eKlStXRt2mTZuiLr0u0/trfHw86tJzMmPGjKjbtm1b1KXvhMfDVM1npmp7J6K67+u6x7xmpON33eNtKl1nSqVjT19fX9RdfPHFUZfOV3/nd34n6q655pqoO/XUU6MuHRtLKeXCCy+Muv3790fd7bffHnU33HBD1KXPv3TNMeU30gEAAAAAoIKFdAAAAAAAqGAhHQAAAAAAKlhIBwAAAACAChbSAQAAAACggoV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKBCe90bbG3N1ubb27Ndp11bW9uUdC0tLVF3PPadHpv0M6bbW7ZsWdRNTk5G3eHDh6Pu3HPPjbpNmzZF3cTERNR1d3dHXSo9LqXk10Kj0fhpP85rSj9jegyb+c4/rY6OjqgbGxs7zp/k2KTn8kQYo+r+jL29vVG3fPnyqDt48GDUrVixIupuvvnmqHvb294Wden3rfuZkT7Hm9l3M9usU7rf9Hu8Eeo+plN1v9Y99yillNHR0ajr7OyMupGRkajbunVr1M2aNavW7ujRo1H3wgsv1No98cQTUZcev+uuuy7q0jlFM9dMus0FCxbU2j3++ONRNz4+HnXpHOdYpPuY7u9wzcx7Es1cb+l8N/2Mc+bMibpFixZFXTrHHB4ejrq+vr6oS49hOnbPnj076gYHB6MuvfbfiPeZn6Tuecp0395rqXv+UffYM1Vz3WaO/VQdw/RZnHape+65J+rSseLtb3971M2fPz/q0vlWOual62V/9Ed/FHWllPJrv/ZrUZd+xnQu+o1vfCPq/uN//I9Rl75DpPxGOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFRoT8OWlpaoa2trq7VL99vamv2dQN3fo6OjI+qOxzab2Xeiq6sr6g4fPhx1o6OjUTc+Ph51CxcujLrBwcGoO3r0aNT19fVFXfo9Go1G1JVSyuTkZO3bTExMTERdek2n3+ONkH63uqVjVKq9PRu+mxkn0jY97+l3Trv0OjrzzDOj7siRI1GXjikvvfRS1N1yyy1R98u//MtRNzw8HHV1n49m20R6bU3V9o5Fes/WPU9J1b3fdHtjY2NRV0o+Rq1YsSLq0uf2fffdF3XnnHNO1PX29kbd448/HnUPPvhg1KVzhe3bt0fdpz71qaibNWtW1A0NDUVdei+Vkl9fPT09UXfBBRdE3e233x516X2ydOnSqDsWdb/Dpeep7jlF3Z+vGekYlZ739N0sPTadnZ1Rt2fPnqibO3du1KXnZPbs2VG3aNGiqNuyZUvUHY/5UWo6vSOdLOo+n1O1zpRK91vK1F3r6XdO15nS9/kzzjgj6p566qmo27p1a9S98MILUTdv3ryoS+cezzzzTNR9//vfj7pSSvnt3/7tqLv88sujLn1Obtu2LerSMTR9/qX8RjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAV2tOw0WjUuuOWlpaoa2trm5Lt1d2VUkpHR0etXbrv9Nx1dXVF3djYWNRNTExE3fj4eNTNmTMn6tLPNzIyEnXd3d1RNzw8HHXHw+TkZNSl10Ld11Z6jo9F3WNUqrU1+/vI9PO1t2fDcjrmNXNc0n2nY0UqvccGBgai7sCBA1F3/vnnR92uXbuibvXq1VH3ve99L+quvfbaqEvHxvS+Tq/pZtT9LE8/Y9ql+z0WUzWfqft81n2Omjn2advT0xN16dgzOjoadfPmzYu6F198MeruuuuuqNu/f3/UpWPZ1VdfHXVnnHFG1B0+fDjq0mfQ8XiupU499dSoO++886IuvU+2b98edcci/Sx1jz3pOUr3W/c8qpkxNH0HSd/10rFs5syZUZfOF9Kx4swzz4y6uq+tGTNmRF3d72bH45ppZi0hkb4Tpp+x7nfM6aTuuV/dc9O6r41mpPtO13s6Ozujbs2aNVF3xx13RF1fX1/ULV++POrS4/KBD3wg6i655JKo27FjR9Rt2bIl6ppx7rnnRl36GdPnZHp/putMdY9RfiMdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKCChXQAAAAAAKhgIR0AAAAAACpYSAcAAAAAgAoW0gEAAAAAoIKFdAAAAAAAqGAhHQAAAAAAKrTXvcHW1mxtvq2trdbttbdnX2WqPl8z20y7jo6OWrfX0tISdfPnz4+69JwcPXo06s4444yomzVrVtQdOnQo6tasWRN1Y2NjUTeVGo1G1E1OTkbdxMRE1DVzn5ys0mOfHtMZM2ZE3Vve8paoK6WU/v7+uE2ccsopUZeOKU888UTU3XHHHVH367/+61F3/vnnR93WrVujbs+ePVH30EMPRd2HP/zhqBscHIy6qXyupftOn1d1b++NMFXHoO65QjrmdXV1RV0ppYyMjERd+jweHx+PuvQY7t+/P+o2btwYdQcPHoy6ffv2Rd1FF10UdVdffXXUHTlyJOrSayudezRzv9a978WLF0fdz/zMz0Td7Nmzoy4dv49F3eN53WNK2tW933ReVkr+TvPCCy9EXV9fX9StWLEi6lauXBl1AwMDUVf386ruOXB6PlLpu/dUmqpneTqGHot0bSGVXm/pftNjUPexambenp73dB6V3hPvfe97oy6d93zpS1+Kurrfl5csWRJ1S5cujbr0fj377LOjrrOzM+quuOKKqCullAsvvDDq/vzP/zzq0ufLsmXLom6q1pmsbgEAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAECF9jRsaWmJura2tqhrbc3W8Kdqe+3t2aFJu1Lyz5h2Y2NjUffSSy9F3Zw5c6LuiSeeiLqDBw9G3ZEjR6JufHw86tJzfPjw4ajr6uqKupGRkahrRqPRqHV76X08MTERdennm5ycjLqTWXrs02O6ePHiqFu2bFnUlVLKXXfdFXXbt2+PugsvvDDqrrrqqqhL79l9+/ZF3fe+972oe9e73hV1Tz/9dNSlY236+a655pqoS8fGtCullI6OjqhLr/9U+pyse7/HopnjWuf20mMwVV0z0vExvT6WLl0adY888kjUbdmyJerSz5d+3/Q+/OAHPxh16TM7vQbTOUV6XJpR9/xj5syZUbdt27aou/rqq6Nu4cKFUXcs6n7nSrv0+q37GZbuNx0nmpHOozZu3Bh1g4ODUdff3x91M2bMiLp0nE+vhfnz50fdggULoq6zszPqptNc4Sep+1jX7Y04hul4nnbpsUq3lz7r0q7u79vMvoeHh6PuH//jfxzvO/Hwww9HXTp+p+tWzz77bNSlrrjiiqhbsmRJ1KXPofe+971Rlz4LSinlsccei7rnnnsu6nbu3Bl1GzZsiLp0Pbbu+aDfSAcAAAAAgAoW0gEAAAAAoIKFdAAAAAAAqGAhHQAAAAAAKlhIBwAAAACAChbSAQAAAACggoV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAK7VO149bWbA2/ra2t1u21t2dfue6ulPy7dHV1Rd3ChQujbmBgIOoOHDgQdb29vVE3ODgYdcPDw1E3MTFRa7dv376o6+joiLr0Gky7UkppNBpRl37ndHvpNThz5syoSz/fsUi/Wyq9X1Pp5+vp6Ym6/fv3R91DDz0UdaWUMjQ0FHXpsbn33nuj7umnn4661atXR92cOXOi7m/+5m+i7rzzzou67u7uqEuP36ZNm6Ju69atUXf22WdH3cjISNSVUkpLS0vUpeNe3dtLTU5O1rq9Y9HMvCJR97Gfyv2Oj49HXTpPWbFiRdSlY8q2bduiLh3n0+tyzZo1Ubds2bKoO3r0aNSl5zgdG9N5YzPqHivS+cyqVauiLn0e3HHHHVH3oQ99KOpeS9337HQfU9Ju8+bNUVdKKXv37o269LynY0V/f3+tXfr5Dh06FHXpe0U6xh+Pd65E3dd0KfV/xrrvk7rfr45F+kycqs88VeeymXnj6Oho1J122mnxNhN79uyJuvnz50fd0qVLo+7RRx+NujvvvDPqZs+eHXXPPPNM1J177rlRd+ONN0ZdOq9N91tKPs6vXbs26h544IGoS+dR6Vpd3fxGOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFRoT8NGoxF1bW1t2Y7bs12n22tpaZmSrhmtrdnfW3R3d0fd3Llzo+6d73xn1H3rW9+qdb+XXXZZ1D300ENRlxocHIy6gwcP1rrf46Gzs7PWLr3vDhw4EHX33ntv1D366KNR95nPfCbq3ggTExNRN1Vj1NjYWK3bK6WUhQsXRt3u3bujbubMmVHX398fdbNmzYq6RYsWRd3IyEjUfeELX4i6c889N+r6+vqibt68eVF3yy23RN35558fdem1VUp+/U936dj4Rpiq+Uw6R0nVvb1mpM/EJUuWRN3KlSujbs+ePVE3PDwcdUeOHIm6G264IerS+dF3vvOdqEvnCv/oH/2jqFu1alXUjY6ORl0ppUxOTkZd+sxPr60rr7wy6r7+9a9HXTPj8k+r7ne4jo6OKdlv2qVj1OzZs6OulFLGx8ej7gc/+EHUbdu2Lere+ta3Rt2ll14aden86M4774y69L5Zvnx51A0MDERdet+k6xzptZWOO6Xk1+F0n28dj7WT/1d6nlLpMU3PUXoM0vuh7rGxlHwecN5550VdOlak86MFCxZEXfqut2zZsqhLj/XQ0FDU7du3L+r+7u/+Lure/e53R106X23muZY+y9/znvdEXfqcfPLJJ6MuHefrHkP9RjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUaE/DycnJqGttzdbm6+5aWlqmpOvo6Ii6Uko5ePBg1B09ejTqenp6om7BggVR12g0ou6b3/xm1J1++ulR19vbG3V33XVX1D3//PNR95a3vCXqUrNnz4669JoupZQ9e/ZE3caNG6PuBz/4QdTdfffdUffoo49GXVdXV9R95jOfibrXko5RUyW9v1JtbW1R194eD/PlkksuibpFixZF3SOPPBJ14+PjUZcew76+vqg77bTTou7xxx+Puu985ztRd+GFF0Zd+vm++93vRt3HP/7xqDvjjDOirpRSxsbGoi59ptY9N0il99OxSO/F6T4/mkrpeUqfOaecckrUXXDBBVG3Y8eOqHv55ZejLr1mHnrooai7/fbbo25wcDDqTj311Kh7+OGHoy6dJ69cuTLqSimls7Mz6tJjnd4n6XPoHe94R9Sl7wbHYqrGijdi/H0tx2PMS+dH6TvIgw8+GHXpu9nP//zPR938+fOjLr1n77nnnqj71re+FXXnnHNO1A0PD0ddOg9Nr5njcU2n+07nynVf/3XPy15L3WNU+u6YdnW/66XS67eUUubOnRt1M2fOjLp9+/ZF3eHDh6Nu+fLlUbds2bKou/jii6MuHWv7+/ujLn0/+rf/9t9G3bXXXht16Zj89NNPR10ppWzatCnq5s2bF3WrV6+OunvvvTfqdu/eHXXp50v5jXQAAAAAAKhgIR0AAAAAACpYSAcAAAAAgAoW0gEAAAAAoIKFdAAAAAAAqGAhHQAAAAAAKlhIBwAAAACAChbSAQAAAACggoV0AAAAAACo0J6Gra3ZmnvdXVtbW61de3v2lRuNRtStWLEi6kopZcaMGVG3adOmqPuf//N/Rt1FF10UdRdccEHU3XnnnVF3yy23RN173/veqDvnnHOi7qWXXoq6Rx99NOqGhoai7sEHH4y6b33rW1HXzDZ37doVdel3Sa//WbNmRd3w8HDUHYv0M9dtcnIy6tIxLx2j0q6lpSXqmpGOFevWrYu69Drfvn171C1YsCDq0vth+fLlUffEE0/U2p1yyilRlz7/0jH5s5/9bNSVUsrY2FjU1T03SKXHpu79vhHSezv9bsdjrEh0dHTEbXq9pePynDlzom7+/PlRlz4T+/v7o667uzvqHnjggaibN29e1KV2794ddekz49ChQ1G3bdu2qCullK6urqh7/vnn420mrrrqqqhbtmxZ1KXvEMdiqt7NUnWPZRMTE1F3//33R10p+Rh1xhlnRF1vb2/Uffe73611ex/5yEdq3d7ixYuj7rHHHou673//+1E3Ojpaa3c8nqfpNtPnWt1zg7o/37GYqne9uqVjT3rsjxw5Eu/7yiuvjNvEwMBA1D399NNRl16/GzZsiLr03k7f9Z588smo+8QnPhF1v/7rvx516VrK3r17oy59VpVSyp49e6Ju586dUZeu1aXS51Az3zlx4r05AgAAAADAG8hCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFChve4NtrS0RF1bW1vUtbZma/3pftPtpZ8v3W8ppcyaNSvqLrrooqjbunVr1H31q1+NulNPPTXqfuEXfiHqfvM3fzPqNm7cGHVXXHFF1L3nPe+Juvvuuy/qPvrRj0bdU089FXWDg4NRV0opnZ2dUTcxMRF1s2fPjrqurq6oGxgYiLqOjo6oeyNMTk7Wur1GoxF16TlK1T3mNSO9hpctWxZ1733ve6PuT/7kT6Ju06ZNUXfVVVdFXXoMx8bGom7Lli1Rd+jQoahLn1fpWHvw4MGoKyUfK+q+79LvfCKqex7VzDwlUfe8rJlzmV5H7e3Z9La7uzvq0s+YPuvS7R09ejTq0vllf39/1I2MjERdX19f1D3++ONRN2PGjKhLv28p+WdMn+W7d++Ouptvvjnq3v/+90fd008/HXXpXPm1pPd23V3d43ndz+xdu3bF+06fs3Pnzq21S+dbX/nKV6LuyJEjUffzP//zUbd69eqoO+uss6Lu29/+dtSl0vv/eMy9676f6n7mp6bTvCw9n1N17NPPl855RkdHo66UfG0hlc6j0v3+4R/+YdT9y3/5L6Nu3bp1UXfjjTdG3YEDB6IufWdNz136Tphq5l0vva537NgRdema2eLFi6MuvbbSuW3Kb6QDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABAhfY0HB8fP56f45g1Go2om5ycjLqOjo6oGxwcjLpSSvmzP/uzqFu2bFnUvfWtb426HTt2RN19990Xdddee23UnX/++VH31FNPRd2RI0eibu3atVF39OjRqPvrv/7rqBseHo669FotpZTW1uzvutrbs1t5z549UTdv3rxa95ueu2MxMTERdekYkH63dL9tbW1Rl57z4yG9NtPxsa+vL+rGxsaibvXq1VH31a9+NequuuqqqEvHspGRkahLnxvp2N3d3R11+/fvj7qBgYGoK6WUhQsXRl1636XXf9333RuhpaUl6tJjkG4vle43PaZ1f75m9PT0RF1nZ2fUpWNeV1dX1KXHML1vDhw4EHVz586NumuuuSbqrrjiiqhLP9+2bdui7vnnn4+6UkpZunRp1KXzlBdffDHq0vG7t7c36vr7+6PuWEzVGJVuL70P676/1q9fH3Wl5M/j733ve1E3f/78qHv3u98ddVu2bIm6v//7v4+6D37wg1F39tlnR926deui7plnnom6J554IurS+Vv6btCMqXqWp9L75I2QrkelnzmdS6ZjTyo952nXzHVZ9zU8a9asqEvnZZdddlnUff3rX4+6iy++OOrSY/27v/u7tW4vvVbTd+VU+k5YSn7fHTx4MOp27doVdRdccEHUzZw5M+rqHhv9RjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUaK97g62t2dp82rW0tNS6vba2tlq3l3allDJjxoyou/POO6Nu7ty5UXfZZZdF3csvvxx1v//7vx91L774YtSNjo5G3fPPPx91fX19Ubd8+fKou+CCC6LukUceibp9+/ZFXSml7N27N+rS79LZ2Rl1Bw4ciLr0Gkz3eywmJyejLr1nx8fHo669PRtGJyYmoq5u6RhaSilLliyJuvTeHhwcrHW/559/ftR997vfjbq///u/j7rPfvazUdff3x916XFJr+l0nDh48GCtXSn5uUu/Syp9lk8ndc97Go1GrftNj2nd87K6r42p1NXVVWu3f//+qDty5EjU/df/+l+j7m1ve1vUpXOFjo6OqEvHnjVr1kRdKaUMDAxE3b333ht1l1xySdRdeOGFUTc2NhZ16Vz+WEzVu1mqmflMYt68eVF39OjReJvp9fbYY49FXTpWdHd3R93MmTOjLn2Xeuihh6IuvW/Se/vss8+Ouh07dkTd008/HXXr1q2LumbU/f5S9xwinRuk2zsW6btUOq6m20vPUbrf9Jmddum4U0r+nF24cGHUpe/4K1eujLrTTjst6p555pmou/vuu6Pu4osvjrrLL7886lI9PT1Rl84H9+zZE3W7du2KulLy6z99VqZrJ+ka4fe///2oS9+/zzvvvKjzG+kAAAAAAFDBQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQoT0NJyYmom5ycjLqGo1G1LW2Zmv9LS0ttW4v/XyzZs2KulJKOeOMM6Ju8+bNUffDH/4w6vbu3Rt1CxcujLr08/X19UXdypUro27nzp1Rt2bNmqjr7e2NuhUrVkRdf39/1B0+fDjqSimlo6Mj6nbv3h11s2fPjrrR0dGoGxoairr0WB+L9DOn2traoi4d89Kxp27pNVRKKTNnzoy69Drat29f1J166qlRt2TJkqg77bTTom54eDjq0ut3+fLlUXfkyJGoS6/pdExJnwXpeSullM7OzqhL5xDpfZeaqvvutaTzlLq7uk3VvKyUfDxLr8uRkZFau/S7pM+N9N7u7u6Ous997nNR9+lPfzrq0jH5a1/7WtSlY2g65ymllO985ztRd+mll0bdlVdeGXUDAwNRl75vvBHzqLrv2XR76bhf93iejhPpOSqllKVLl0bdO97xjqi77777oi59vvf09ERd+vkuuuiiqEvPcfrumB7nM888M+q+/vWvR92HPvShqGvm+TxV138qfV69Ee6///6oS49p3XPT9vZsaW18fLzW7aVrEKWUcvrpp9fapeNoes+m4+3atWujLh0bL7zwwqibKuk767Zt26KumfWo9HpNt9nV1RV1d9xxR61dOob+yq/8Sra9qAIAAAAAgDcpC+kAAAAAAFDBQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABAhfY07O7ujrqOjo5sx+3ZrltaWqKutTX7O4G2trZat9doNKKulFIOHDgQdUNDQ1G3evXqqOvs7Iy6kZGRqLvooouibsWKFVG3fPnyqEuvmZdffjnqNm7cGHWp9B7ZvXt3vM30GL744otRd/Dgwair+5pp5j75afX19UXdxMRErd3k5GTUpdIxKu3GxsbifR86dCjqFi9eHHVbt26Nup07d0Zdeo+deeaZUXfWWWdFXXqdp9fCvHnzom7Hjh1R19XVFXXp8zm9DkrJr8O6pc/o6aTu+Uc6P0rPe7q99DpPnyPpWNuM9J44fPhwrd34+HjUpcew7nO8b9++qPvCF74QdXPmzIm6U045JeqGh4ej7vvf/37UlZLPMa+55pqoS+fo6blLvRHzqLrHnnR7dY/n6efr6emJuqVLl8b7Xrt2bdQ99dRTUZd+xlWrVkVdOi5//OMfj7pLLrkk6vbv3x916Rg1OjoadenxS9/N6r72m5HOIep+pk6n+Vb6bE+lawup9Fmcdqn0/aiUUp555pla951K333StYp0HpWuD+zatSvqVq5cGXWpl156KerSMfSFF16IunRsLCWfAx85ciTq6n5Gp9urex41fUZGAAAAAACYhiykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFSwkA4AAAAAABXa0/D000+PukajEXV79uyJusHBwajr7OyMuu7u7qhLv8fExETUlVLKsmXLou6SSy6JumeeeSbqxsfHo2716tVRl36PNWvWRN3KlSuj7tChQ1F34MCBqBsYGIi6vXv3Rt3hw4ejbmRkJOpKKWV4eDjq5s2bF3UHDx6MuvS6Hh0drXV7x+K8886LuvTeTu+bdHstLS1R19HRUWuXjqGllPLcc89F3Zlnnhl16bi8ZcuWqKt7jJo1a1bUpffh9u3bo661Nfs77HSsSK+t9HwcOXIk6krJr//JycmoSz9jegzb2tqi7o2QjoPp+Uy7dL/t7dmUMD326X7TsbaU/DOm+06f2+k9kV7ndV+/6X0ze/bsqEu/R3r80nFi48aNUffWt7416kop5ROf+ETU1f3Mr9sbMY+a7tL7Ib1+j8e5TN8t0s/Y19cXdaeeemrUpc+N9F00/Xz79++PuvQdbseOHVG3e/fuqEufLalm5h7p86Du7aXX4HQae9J3n3Q8T8973XPJuo9pug5QSimPPfZYrftOpfOU9JykaxDpuUuvmfTc1f3u2N/fH3WpZsaddFxOx5S677v0nKSfL+U30gEAAAAAoIKFdAAAAAAAqGAhHQAAAAAAKlhIBwAAAACAChbSAQAAAACggoV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKBCexqOjY1FXUtLS9RNTEzUut/W1uzvBDo6OqLu8OHDUTd//vyoK6WUCy+8MOr27dsXdS+++GLUDQ0NRd2cOXOirre3N+qWLFkSdem5S6+F9PumhoeHo+7gwYO17reUUvbs2RN1y5Yti7oZM2ZE3ejoaK3d5ORk1B2L9Pin11vatbW1RV17ezbcpmPjgQMHoi79fM1sc9WqVVFX972djlHp/ZCOoWeddVbUpd/3yJEjUddoNKIu1dnZGXV33XVXvM29e/dGXXpdp58xvZ/SZ36631/6pV+KumORXkepdPxNr7d0e+n3SK+NUkqZNWtW1I2Pj0fd4OBgvO9E3WNeOn6nxyWdA6Rz+dTDDz8cde9617ui7oYbboj3nc7h6h5v0+2l1yr5WJHeN0ePHo26Zuaw6fW2aNGiqEuvj/Q7p+9m6ftt+iweGBiIuvT9e//+/VF36NChqDvllFOiru7n84mgmfeI6aLu89TMPGUq9PT0xO3mzZujbtOmTVF37rnnRt3IyEjUpWNe3fP7dF62Y8eOqEuvmXTdL13fSr9vM/PfutdYUnXPRev25nsaAAAAAABAEyykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQIX2NOzo6Ii61tZsbb69Pd51pKWlJera2tqirq+vL+r27dsXdaWUMjo6GnWLFi2KutNOOy3qNm3aFHUzZ86MuvHx8ahLjYyMRF16rIeGhqIuvRZSdV/TpeTXzPDwcNSl92dXV1fUpZ9vcHAw6o5FOkal5z09VpOTk1GXSj/fjBkzat1eKfn5TL/z+vXro27jxo1Rd/jw4ai79NJLo+7mm2+OurrH0HSMSq/pdOxJr4WXXnop6kopZfbs2VGXXjONRqPW7dXtl37pl37qP1v3Myed96TXUbq9dGxMNTOnmDt3btRNTExE3djYWNSl91i637rH2vTz1d3t3Lkz6k499dSo+8Vf/MWoS+eNzUiv/7RLpeNCem0di6kap9PvVvc5Svebft9SSlmwYEHU7dq1K+rSY3j06NGoS98x0/eA9P0jHfOOHDkSden3Tcf4OXPmRF36PG1mjpK2U/VeMp2k42Xd73qpuse89Ht0dnZGXSn58/3++++PunPPPTfq+vv7o25gYCDq0rWF9JykY3J3d3fULV26NOrSsTa1f//+qEuPczPbrFvda4518xvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUKG97g1OTk5G3cTERNS1tLREXVtbW9Sl0u0dOHAg3ubBgwejbs6cOVG3ZMmSqHvqqaeirr09uxzSc7x3796omzlzZtQdOnQo6gYHB6Mu/R5pl0qv6VJKaTQaUXf48OGoS6+t8fHxqOvq6qp1e2+E9JimWluzv49Mu6mUjntbtmyJure//e1Rd9ppp0Xdrl27oi4dG9Pv+7WvfS3qrrzyyqir+/nX0dFR6/bSMbSU/BjW/Rnrvp+aGZeni3QsS59h6TFN5wrp/GjhwoVRV0opPT09Ubd///6oGx0djbr0Oh8bG4u6zs7OqEvPSXqO0+v86NGjUZeej1/91V+NulQz87K6j2G6vfRYT6exp+7vlo4VUzXup/dr2pWSP+vSsScdK9L9pvds+vnS+cLQ0FDUpWNPur303C1YsCDq6l7nKKX+NYy6NfNdTjTpPCo9R3XPo9LtNXMNdXd3R126fpReH9u3b691e+mYl57jnTt3Rl16TtJ30ZGRkah79tlno66/vz/q0rG22fbNZPqv7AAAAAAAwBSykA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUaE/DRqMRdS0tLbVuL+1S6fba27NDMzQ0FO9769atUffWt7416jo6OqJu9uzZUdfamv29yoEDB6Lu2WefjbrVq1dH3YwZM6IuPcdjY2NRNzk5GXUDAwNRN2/evKgrpZR9+/ZFXXod9vX1RV36nScmJqKuq6sr6qaT9Bik982JoLOzM+r27t0bdbt37466hQsXRl16z6b7Pf/886PuxRdfjLpdu3ZFXSr9vm1tbbV26X6badN9p8/edOxJpXOXE1Hd87fR0dGoS8/RKaecEnWllDIyMhJ1+/fvj7r02Zl+l/R+SI9hb29v1HV3d0ddOm985plnou6Tn/xk1C1YsCDq0jlPOp6UUv97xFTNDer+Hq8lPa7pd0uPVTPns0513/+l5PdYemzWrVsXdf39/VF38ODBqEvfaXbs2BF1L730UtSlY0A61qbnbsWKFVGXauaanu7vEVN1fx6LuueI6fhb97kcHx+vfb/pO3l6z6bzsnS8TT9f2qXvtun20jEvHbvTd8f0XfTw4cNRNzw8HHWl5NfhVI0Vda/ppab3yA0AAAAAAFPMQjoAAAAAAFSwkA4AAAAAABUspAMAAAAAQAUL6QAAAAAAUMFCOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQoT0NG41G1LW0tETd5ORk1LW2Ts1af/r52tra4m0+/PDDUfeWt7wl6rq7u6Nu4cKFUdfenl0Oe/fujbrBwcGo6+npqbUbGRmJuiNHjkTd6Oho1A0MDERdet6Oh/ScdHZ2Rl16rDs6OqLuWKRjVN2masxLt9eMdDwbGxuLuqeeeirq1q9fH3WzZs2KuvQYdnV1Rd3HPvaxqNu4cWPUbd26NerS+2tiYiLqUs08d9P7ru7reqq2dyzSsSLt0vs17dJxf+fOnVG3Zs2aqDt69GjUlZI/Z4eHh6Mufb6n854DBw5EXXrfpPOF3t7eqNu2bVvUrVixIuquvvrqqDt06FDUpfPQ4yEdA9L7qe5xeTqp+x2p7vE33V56jpoZo9Lxe86cOVHX19cXdenYuG/fvqhLx7IdO3ZE3UsvvRR1u3fvjrr0nKTz1VWrVkVdaqrWL5rZ93SaH6Xqnh/Vvd+630WPx7FP5xX79++PunTuuHTp0qhLv3N6TtJ5xezZs6Puhz/8YdSlx6/u+zB9dxwaGoq6ZvZd932Sbm+q1k6mz8gIAAAAAADTkIV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKCChXQAAAAAAKhgIR0AAAAAACpYSAcAAAAAgAoW0gEAAAAAoEJ7GjYajeP5OX6iycnJWrfX0tISden37erqive9ffv2qPvhD38YdevXr4+6uXPnRt3g4GDUtbZmf/+Sft+ZM2dGXVtbW9Tt27cv6sbHx6Nu//79Ubd3796oO+WUU6KulFL6+vqibmBgIOoOHz4cdQsXLoy6sbGxqHsjxo90rEjHgPQ6T79but+pNDExEXUdHR1Rt3nz5qhbtmxZ1C1evDjq0mshvWfnzJkTdYsWLYq6p556KuqOHj0adem1lZ639vZ4akAT0vFyquY9Bw4ciLr0+dDb2xt16TO2lFIOHjwYdbt27Yq6xx9/POqefPLJqHv55ZejbmRkJOrS+VF/f3/UzZo1K+o+85nPRF06L0u/b/rcPR7qvu9S6Rwinb+diNIxKr3e6r6ORkdH4zbdd/o8Tr9z+txO35HSsSwda9Munfek0uOczkNPBHXfT1O1BvRapuqz1P2uV/dYlq5plJKPFemc8MiRI1G3evXqqEvnyul3Hh4ejrp0npJeC+m8rKenJ+rSNcf0uKTft5T8M9ats7Mz6tJz0syzPOE30gEAAAAAoIKFdAAAAAAAqGAhHQAAAAAAKlhIBwAAAACAChbSAQAAAACggoV0AAAAAACoYCEdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKBCexq2tta75t5oNKKupaWl1v1OTk7Wut90e6WU0tHREXUPPfRQ1J1xxhlRN2PGjKh7+eWXoy79zsPDw1G3efPmqJs7d27UDQ0NRV1nZ2fUpZ8vNTIyEre9vb1RNzAw8NN+nNd05MiRqOvp6al1e8diYmIi6tKxrJl7O9HW1lbr9k4E6RjwxBNPRN3ixYujLr0WxsbGoi4dG9NznD4L0udQOsanx6UZdT8r29uzaclUzQ2Oxc033xx16XWUPsPS58P5558fddddd13U1T2nKKWUPXv2RN3jjz8edenYs2PHjqg7cOBA1HV1dUVdOp9Jj+G6deui7o477oi6o0ePRl3d7xDj4+O1bu94SM9JemzWr19/LB/npFD3OJ0e+3SsLSWfV6TSeVQ6z+7v74+67du3R93OnTujbt++fVGXSq+F9N0xnV9OpbrnPdN9vyeidH0rnY8fj3l7Ou6lz/cnn3wy6t75zndGXTqWpV06XxgdHY26dI6ejo0rV66MurqvheNxbdW97/Tcpc/duueifiMdAAAAAAAqWEgHAAAAAIAKFtIBAAAAAKCChXQAAAAAAKhgIR0AAAAAACpYSAcAAAAAgAoW0gEAAAAAoIKFdAAAAAAAqGAhHQAAAAAAKrQ0Go3GVH8IAAAAAACYrvxGOgAAAAAAVLCQDgAAAAAAFSykAwAAAABABQvpAAAAAABQwUI6AAAAAABUsJAOAAAAAAAVLKQDAAAAAEAFC+kAAAAAAFDBQjoAAAAAAFT4/wEbWmXAaFoaJQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "def plot_samples(x_data: np.array, y_data: np.array, num_samples: int = 5):\n",
        "    \"\"\"\n",
        "    Plot a random sample of images from the dataset.\n",
        "\n",
        "    Args:\n",
        "        x_data (numpy.ndarray): Images set to plot.\n",
        "        y_data (numpy.ndarray): Labels of the images.\n",
        "        num_samples (int): Number of samples to plot.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Select random indices to plot\n",
        "    indices = np.random.choice(range(len(x_data)), num_samples, replace=False)\n",
        "    selected_images = x_data[indices]\n",
        "    selected_labels = y_data[indices]\n",
        "\n",
        "    # Create the figure using matplotlib\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
        "    for i, ax in enumerate(axes):\n",
        "        # Reshape the image to 28x28\n",
        "        image = selected_images[i].reshape(28, 28)\n",
        "        label = selected_labels[i]\n",
        "\n",
        "        # Show the image and set the title\n",
        "        ax.imshow(image, cmap='gray')\n",
        "        ax.set_title(f\"Label: {alphabet[label]}\")\n",
        "        ax.axis('off')  # Hide axes\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_samples(x_train, y_train, num_samples=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynoxc2Zq8ATT"
      },
      "source": [
        "### Ecuaciones para nuestro modelo\n",
        "\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ANpmEL8ATT"
      },
      "source": [
        "### Funciones adicionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoBZ8o-e8ATT"
      },
      "source": [
        "#### Mini batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Minibatches function is important for training the model because it allows to split the data into smaller chunks to be trained in parallel.\n",
        "It allows to train the model faster and more efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2wmHrxRl8ATT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_minibatches(mb_size: int, x: np.ndarray, y: np.ndarray, shuffle: bool = True):\n",
        "    '''\n",
        "    Function to create minibatches of the data for more efficient training.\n",
        "    This function is used to create subsets of the data to be used during training.\n",
        "    Args:\n",
        "        mb_size (int): Size of the minibatches.\n",
        "        x (np.ndarray): Input data.\n",
        "        y (np.ndarray): Labels.\n",
        "        shuffle (bool): Whether to shuffle the data before creating minibatches.\n",
        "    Returns:\n",
        "        generator: A generator that yields minibatches of the data.\n",
        "    '''\n",
        "    # Ensure the number of samples in x and y are the same\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0] # Get the total number of data samples\n",
        "    if shuffle: # Shuffle the data if shuffle is True\n",
        "        idxs = np.arange(total_data) # Create an array of indices and shuffle them\n",
        "        np.random.shuffle(idxs)\n",
        "        # Reorder x and y according to the shuffled indices\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]  \n",
        "    # Generate minibatches\n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVH6Bta18ATU"
      },
      "source": [
        "## Nuestra clase Linear, ReLU y Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This class is used to create a tensor class. It helps to keep track of the gradients and the operations that are performed on the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "class np_tensor(np.ndarray): pass # subclassing np.ndarray to create a tensor class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6XuMGLB8ATU"
      },
      "source": [
        "###  Clase Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Linear class is a layer that performs a linear transformation of the input data using weights and biases \n",
        "and computes the forward and backward passes of the layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Linear():\n",
        "    def __init__(self, input_size: int, output_size: int):\n",
        "        \"\"\"\n",
        "        Function to initialise the parameters of the linear layer using Kaiming He.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Number of pixels in the input data.\n",
        "            output_size (int): Number of neurons in the layer.\n",
        "        \"\"\"\n",
        "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor) # init weights\n",
        "        self.b = (np.zeros((output_size, 1))).view(np_tensor) # init biases\n",
        "\n",
        "    def __call__(self, X: np_tensor) -> np_tensor:\n",
        "        \"\"\"\n",
        "        Function to compute the forward pass of the linear layer.\n",
        "\n",
        "        Args:\n",
        "            X (np_tensor): Input data.\n",
        "\n",
        "        Returns:\n",
        "            np_tensor: Z: Output of the linear layer.\n",
        "        \"\"\"\n",
        "        Z = self.W @ X + self.b # forward pass\n",
        "        return Z\n",
        "    \n",
        "    def backward(self, X: np_tensor, Z: np_tensor) -> None:\n",
        "        \"\"\"\n",
        "        Function to compute the backward pass of the linear layer and update the gradients of X, W and b.\n",
        "\n",
        "        Args:\n",
        "            X (np_tensor): Input data (output of previus layer).\n",
        "            Z (np_tensor): Output of the linear layer.\n",
        "        \"\"\"\n",
        "        X.grad = self.W.T @ Z.grad # gradient of the input\n",
        "        self.W.grad = Z.grad @ X.T # gradient of the weights\n",
        "        self.b.grad = np.sum(Z.grad, axis=1, keepdims=True) # gradient of the biases  \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9brqz1T98ATU"
      },
      "source": [
        "### Clase ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ReLU activation class is a function that applies the ReLU activation function to the input data.\n",
        "The ReLU activation function is defined as f(x) = max(0, x).\n",
        "The function returns the output of the ReLU activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReLU():\n",
        "    def __call__(self, Z: np_tensor) -> np_tensor:\n",
        "        \"\"\"\n",
        "        Function to compute the forward pass of the ReLU activation function.\n",
        "\n",
        "        Args:\n",
        "            Z (np_tensor): Input data (output of the linear layer).\n",
        "        \n",
        "        Returns:\n",
        "            np_tensor: A: Output of the ReLU activation function.\n",
        "        \"\"\"\n",
        "        return np.maximum(0, Z)\n",
        "    \n",
        "    def backward(self, Z: np_tensor, A: np_tensor) -> None:\n",
        "        \"\"\"\n",
        "        Function to compute the backward pass of the ReLU activation function and update the gradients of Z.\n",
        "\n",
        "        Args:\n",
        "            Z (np_tensor): Input data (output of the previus linear layer).\n",
        "            A (np_tensor): Output of the ReLU activation function.\n",
        "        \"\"\"\n",
        "        Z.grad = A.grad.copy()\n",
        "        Z.grad[Z <= 0] = 0 # values less than 0 have zero gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "divDUUj68ATU"
      },
      "source": [
        "### Clase Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sequential class to create the neural network with multiple layers. This class has methods to compute the forward, backward and update the parameters of the network.\n",
        "Also, it has a method to predict the class of the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class Sequential_layers():\n",
        "    def __init__(self, layers: list[np_tensor]):\n",
        "        \"\"\"\n",
        "        Function to initialise the layers of the neural network.\n",
        "\n",
        "        Args:\n",
        "            layers (list[np_tensor]): List containing objects of type Linear, ReLU.\n",
        "        \"\"\"\n",
        "        self.layers = layers\n",
        "        self.x = None # temporary variable to store the output of the layers\n",
        "        self.outputs = {} # dictionary to store the activations of the layers \n",
        "\n",
        "    def __call__(self, X: np_tensor) -> np_tensor:\n",
        "        \"\"\"\n",
        "        Function to compute the forward pass of the neural network.\n",
        "\n",
        "        Args:\n",
        "            X (np_tensor): Input data.\n",
        "\n",
        "        Returns:\n",
        "            np_tensor: Output of the neural network.\n",
        "        \"\"\"\n",
        "        self.x = X \n",
        "        self.outputs['l0'] = self.x # in the layer l0, the input is the input images X\n",
        "        for i, layer in enumerate(self.layers, 1): \n",
        "            self.x = layer(self.x) # forward pass for each layer\n",
        "            self.outputs['l'+str(i)]=self.x # store the output of each layer\n",
        "        return self.x # output of the neural network (output of the last layer)\n",
        "    \n",
        "    def backward(self):\n",
        "        \"\"\"\n",
        "        Function to compute the backward pass of the neural network.\n",
        "        Implement backward pass for each layer.\n",
        "        \"\"\"\n",
        "        for i in reversed(range(len(self.layers))): # iterate over the layers in reverse order\n",
        "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)]) # compute the backward pass\n",
        "\n",
        "    def update(self, learning_rate: float = 1e-3):\n",
        "        \"\"\"\n",
        "        Function to update the weights and biases of the layers using gradient descent.\n",
        "\n",
        "        Args:\n",
        "            learning_rate (float, optional): Defaults to 1e-3. Size of the step to update the parameters.\n",
        "        \"\"\"\n",
        "        for layer in self.layers: # iterate over the layers\n",
        "            if isinstance(layer, ReLU): continue # ReLU has no parameters, so we skip it\n",
        "            layer.W = layer.W - learning_rate * layer.W.grad # update weights\n",
        "            layer.b = layer.b - learning_rate * layer.b.grad # update biases\n",
        "\n",
        "    def predict(self, X: np_tensor):\n",
        "        \"\"\"\n",
        "        Function to predict the class of the input data. Output is the class with the highest probability.\n",
        "\n",
        "        Args:\n",
        "            X (np_tensor): Input data.\n",
        "\n",
        "        Returns:\n",
        "            Predicted class.\n",
        "        \"\"\"\n",
        "        return np.argmax(self.__call__(X)) # return the class with the highest probability           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcESjYu78ATU"
      },
      "source": [
        "### Cost Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cost function is used to evaluate the performance of the model each iteration. \n",
        "\n",
        "It measures the difference between the predicted values and the true values.\n",
        "\n",
        "Cross-entropy loss is commonly used for classification problems.\n",
        "\n",
        "It measures the difference between two probability distributions: the predicted and the true distribution.\n",
        "\n",
        "Cross-entropy loss is used with softmax activation in the output layer.\n",
        "\n",
        "It is the negative log-likelihood of the true labels given the predicted probabilities.\n",
        "\n",
        "The goal is to minimize the cross-entropy loss to improve the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "def softmaxXEntropy(x: np_tensor, y: np.ndarray):\n",
        "    \"\"\"\n",
        "    Function to compute the softmax and cross entropy loss.\n",
        "\n",
        "    Args:\n",
        "        x (np_tensor): Input data.\n",
        "        y (np.ndarray): True labels.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Predictions.\n",
        "        float: Cost.\n",
        "    \"\"\"\n",
        "    batch_size = x.shape[1] \n",
        "    exp_scores = np.exp(x) # exponentiate the scores\n",
        "    probs = exp_scores / exp_scores.sum(axis = 0) \n",
        "    preds = probs.copy()\n",
        "    # Cost function calculation\n",
        "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
        "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
        "    # Gradient calculation\n",
        "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
        "    x.grad = probs.copy()\n",
        "    \n",
        "    return preds, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy function is used to compute the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(model, x, y, mb_size: int) -> float:\n",
        "    \"\"\"\n",
        "    Function to compute the accuracy of the model.\n",
        "\n",
        "    Args:\n",
        "        model: Sequential model.\n",
        "        x (np.ndarray): Input data.\n",
        "        y (np.ndarray): True labels.\n",
        "        mb_size (int): Minibatch size.\n",
        "    \n",
        "    Returns:\n",
        "        float: Accuracy of the model\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
        "        pred = model(x.T.view(np_tensor))\n",
        "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
        "        total += pred.shape[1]\n",
        "    return correct/total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l-Sc6Ts8ATV"
      },
      "source": [
        "### Loop de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function allow us to train the model specifying the number of epochs, minibatch size and learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, epochs: int, mb_size: int = 128, learning_rate: float = 1e-3):\n",
        "    \"\"\"\n",
        "    Function to train the neural network. Print the cost and accuracy of the model.\n",
        "\n",
        "    Args:\n",
        "        model (Sequential_layers): Neural network model.9\n",
        "        epochs (int): Number of epochs to train the model.\n",
        "        mb_size (int, optional): Defaults to 128. Size of the minibatches.\n",
        "        learning_rate (float, optional): Defaults to 1e-3. Size of the step to update the parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)): # loop over minibatches\n",
        "            scores = model(x.T.view(np_tensor)) \n",
        "            _, cost = softmaxXEntropy(scores, y) # cost calculation\n",
        "            model.backward() \n",
        "            model.update(learning_rate)\n",
        "        print(f'Epoch: {epoch}, costo: {cost}, accuracy: {accuracy(model, x_val, y_val, mb_size)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuc2YVPI8ATV"
      },
      "source": [
        "### Create your model and train it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define the model architecture as follows:\n",
        "1. Linear layer with 784 input neurons (size of images) and 270 output neurons.\n",
        "2. ReLU activation function.\n",
        "3. Linear layer with 270 input neurons and 180 output neurons.\n",
        "4. ReLU activation function.\n",
        "5. Linear layer with 180 input neurons and 90 output neurons.\n",
        "6. ReLU activation function.\n",
        "7. Linear layer with 90 input neurons and 24 output neurons (quantity of classes).\n",
        "\n",
        "We use the following hyperparameters:\n",
        "Minibatch size: 512\n",
        "Learning rate: 1e-3\n",
        "Number of epochs: 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ROW6UrB68ATV"
      },
      "outputs": [],
      "source": [
        "model = Sequential_layers([Linear(784, 270), ReLU(), Linear(270, 180), ReLU(), Linear(180, 90), ReLU(), Linear(90, 24)]) # defining the model architecture\n",
        "mb_size = 512 # minibatch size\n",
        "learning_rate = 1e-3 # learning rate\n",
        "epochs = 30 # number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, costo: 0.4882164135020039, accuracy: 0.6553262688232013\n",
            "Epoch: 1, costo: 0.03307943757528092, accuracy: 0.7671500278862242\n",
            "Epoch: 2, costo: 0.0063765171077777094, accuracy: 0.7799776910206359\n",
            "Epoch: 3, costo: 0.003474413853323059, accuracy: 0.7836029001673174\n",
            "Epoch: 4, costo: 0.0027098582472112366, accuracy: 0.7824874511991077\n",
            "Epoch: 5, costo: 0.0022903622992035736, accuracy: 0.7844394868934746\n",
            "Epoch: 6, costo: 0.0017172340328123123, accuracy: 0.7841606246514222\n",
            "Epoch: 7, costo: 0.0013885408811787749, accuracy: 0.783324037925265\n",
            "Epoch: 8, costo: 0.0010750659178690514, accuracy: 0.7849972113775795\n",
            "Epoch: 9, costo: 0.0007672376927560854, accuracy: 0.7863915225878416\n",
            "Epoch: 10, costo: 0.0007944103627003767, accuracy: 0.7875069715560513\n",
            "Epoch: 11, costo: 0.0007711081291518612, accuracy: 0.7877858337981037\n",
            "Epoch: 12, costo: 0.0006131670938862508, accuracy: 0.7883435582822086\n",
            "Epoch: 13, costo: 0.0004921632525585882, accuracy: 0.7880646960401562\n",
            "Epoch: 14, costo: 0.0003866100272248586, accuracy: 0.7875069715560513\n",
            "Epoch: 15, costo: 0.00048627905544484294, accuracy: 0.788622420524261\n",
            "Epoch: 16, costo: 0.00042823099203167245, accuracy: 0.7894590072504183\n",
            "Epoch: 17, costo: 0.0004350467037896638, accuracy: 0.7897378694924707\n",
            "Epoch: 18, costo: 0.00037770277504723266, accuracy: 0.7897378694924707\n",
            "Epoch: 19, costo: 0.0003742926016943701, accuracy: 0.7897378694924707\n",
            "Epoch: 20, costo: 0.0003888719321695581, accuracy: 0.7897378694924707\n",
            "Epoch: 21, costo: 0.00029554829597861474, accuracy: 0.7897378694924707\n",
            "Epoch: 22, costo: 0.0003474103466648774, accuracy: 0.7900167317345231\n",
            "Epoch: 23, costo: 0.00025096033571652695, accuracy: 0.7900167317345231\n",
            "Epoch: 24, costo: 0.00026970863451433974, accuracy: 0.7902955939765756\n",
            "Epoch: 25, costo: 0.00020288340691854324, accuracy: 0.790574456218628\n",
            "Epoch: 26, costo: 0.000244857217654639, accuracy: 0.7897378694924707\n",
            "Epoch: 27, costo: 0.00023231515699962665, accuracy: 0.7894590072504183\n",
            "Epoch: 28, costo: 0.0002501136631659381, accuracy: 0.7891801450083659\n",
            "Epoch: 29, costo: 0.00023388415857133007, accuracy: 0.7891801450083659\n"
          ]
        }
      ],
      "source": [
        "train(model, epochs, mb_size, learning_rate) # training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy obtained 0.7975460122699386\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy obtained', accuracy(model, x_test, y_test, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HcdDfYC8ATV"
      },
      "source": [
        "### Test your model on Random data from your test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "_DzsOVQU8ATV"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Real value: \"t\". Predicted value: \"t\"\n"
          ]
        }
      ],
      "source": [
        "idx = np.random.randint(0, len(x_test))\n",
        "plot_image(x_test[idx], y_test[idx])\n",
        "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
        "print(f'Real value: \"{alphabet[y_test[idx]]}\". Predicted value: \"{alphabet[pred]}\"')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
